{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "from collections import Counter\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "#从pyplot导入MultipleLocator类，这个类用于设置刻度间隔\n",
    "%matplotlib inline\n",
    "\n",
    "LayerNorm = torch.nn.LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config():\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size=25000,\n",
    "        hidden_size=512,\n",
    "        num_hidden_layers=3,\n",
    "        num_attention_heads=8,\n",
    "        intermediate_size=2048,\n",
    "        hidden_act=\"relu\",\n",
    "        hidden_dropout_prob=0.1,\n",
    "        attention_probs_dropout_prob=0.1,\n",
    "        max_position_embeddings=32,\n",
    "        type_vocab_size=2,\n",
    "        initializer_range=0.02,\n",
    "        layer_norm_eps=1e-12,\n",
    "        norm_eps=1e-12,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.hidden_act = hidden_act\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.hidden_dropout_prob = hidden_dropout_prob\n",
    "        self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.type_vocab_size = type_vocab_size\n",
    "        self.initializer_range = initializer_range\n",
    "        self.layer_norm_eps = layer_norm_eps\n",
    "        self.norm_eps = norm_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model\"\"\"\n",
    "\n",
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=0)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, input_ids, position=None):\n",
    "        embeddings = self.word_embeddings(input_ids)\n",
    "        if position:\n",
    "            embeddings += self.position_embeddings(position)\n",
    "            \n",
    "        return embeddings\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "\n",
    "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
    "\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        # x : batch_size * max_seq * dim\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)  \n",
    "        # new_x_shape: batch_size * max_seq * attention_heads * head_size\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "        # return shape: batch_size * attention_heads * max_seq * head_size\n",
    "\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask):\n",
    "        # hidden_states: batch_size * max_seq * embedding_dim\n",
    "        \n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "        mixed_key_layer = self.key(hidden_states)\n",
    "        mixed_value_layer = self.value(hidden_states)\n",
    "\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
    "\n",
    "\n",
    "        extended_attention_mask = attention_mask[:, None, None, :]\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "        attention_mask = extended_attention_mask\n",
    "        \n",
    "\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2)) \n",
    "        # batch_size * attention_heads * max_seq_a * max_seq_b\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        attention_scores = attention_scores + attention_mask\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "        \n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "        \n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "\n",
    "        outputs = context_layer\n",
    "\n",
    "        return outputs\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense_1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        self.dense_2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.norm = LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        x = self.dense_1(hidden_states)\n",
    "        x = nn.functional.relu(hidden_states)\n",
    "        x = self.dropout(x)\n",
    "        hidden_states = self.norm(x + hidden_states)\n",
    "\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadSelfAttention(config)\n",
    "        self.norm = LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.feedforward = FeedForward(config)\n",
    "    \n",
    "    def forward(self, hidden_states, attention_mask):\n",
    "        x = self.attention(hidden_states, attention_mask)\n",
    "        hidden_states = self.norm(hidden_states + x)\n",
    "        hidden_states = self.feedforward(hidden_states)\n",
    "\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "class Pooling(nn.Module):\n",
    "    def forward(self, x, mask):\n",
    "        # max pooling\n",
    "        # print('mask:', mask)\n",
    "        extended_mask = mask[:, :, None]\n",
    "        extended_mask = (1.0 - extended_mask) * (-100000)\n",
    "        mask = extended_mask\n",
    "        # print('extended_mask:', mask)\n",
    "        x = x + mask\n",
    "        return x.max(dim=1)[0]\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embedding = EmbeddingLayer(config)\n",
    "        self.blocks = nn.ModuleList([Block(config) for _ in range(config.num_hidden_layers)])\n",
    "        self.pooling = Pooling()\n",
    "        self.prediction = nn.Linear(config.hidden_size, 10)\n",
    "\n",
    "        # self.init_weights()\n",
    "        self.loss_fct = CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels):\n",
    "        hidden_states = self.embedding(input_ids)\n",
    "        for i, layer in enumerate(self.blocks):\n",
    "            hidden_states = layer(hidden_states, attention_mask)\n",
    "        outputs = self.pooling(hidden_states, attention_mask)\n",
    "        outputs = self.prediction(outputs)\n",
    "        loss = self.loss_fct(outputs.view(-1, 10), labels.view(-1))\n",
    "        outputs = (loss, outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "def sentence2ids(args, sentence, word2id):\n",
    "    if args.do_lower_case:\n",
    "        sentence = sentence.lower()\n",
    "    ids = []\n",
    "    # for word in  sentence.strip().split():\n",
    "    for word in  list(sentence.strip()):\n",
    "        if word not in word2id.keys():\n",
    "            ids.append(word2id['<UNK>'])\n",
    "        else:\n",
    "            ids.append(word2id[word])\n",
    "    return ids\n",
    "\n",
    "\n",
    "def load_vocab(args):\n",
    "    import codecs\n",
    "    vocab_path = os.path.join(args.data_dir, 'vocab.txt')\n",
    "\n",
    "    if not os.path.exists(vocab_path):\n",
    "        vocab = Counter()\n",
    "        files = os.listdir(args.data_dir)\n",
    "        for file in files:\n",
    "            if not os.path.isdir(file) and file != '.DS_Store':\n",
    "                # print('file:', file)\n",
    "                f = codecs.open(os.path.join(args.data_dir, file), 'r')\n",
    "                for line in f.readlines():\n",
    "                    text, label = line.strip().split('\\t')\n",
    "                    if args.do_lower_case:\n",
    "                        text = text.lower()\n",
    "                        \n",
    "                    vocab.update(list(text))\n",
    "                f.close()\n",
    "        f = codecs.open(os.path.join(args.data_dir+'/vocab.txt'), 'w')\n",
    "        vocab = vocab.items()\n",
    "        vocab = sorted(vocab, key=lambda x:x[1], reverse=True)\n",
    "        f.write('<PAD>\\n<UNK>\\n')\n",
    "        for _ in vocab:\n",
    "            f.write(_[0] + '\\n')   \n",
    "\n",
    "    with open(vocab_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    word2id = {}\n",
    "    vocab = []\n",
    "    for (index, line) in enumerate(lines):\n",
    "        word = line.strip()\n",
    "        vocab.append(word)\n",
    "        word2id[word] = index\n",
    "\n",
    "    return vocab, word2id\n",
    "\n",
    "def load_dataset(args, word2id, data_type):\n",
    "    data_path = os.path.join(args.data_dir, data_type+'.txt')\n",
    "\n",
    "    # Read Data\n",
    "    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    examples = []\n",
    "    for (i, line) in enumerate(lines):\n",
    "        if len(line.strip().split('\\t')) == 2:\n",
    "            text, label = line.strip().split('\\t')\n",
    "            examples.append((text, label))\n",
    "            \n",
    "\n",
    "    # Convert to features\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        len_examples = len(examples)\n",
    "        if ex_index % 10000 == 0:\n",
    "            print(\"Writing example %d/%d\" % (ex_index, len_examples))\n",
    "\n",
    "        input_ids = sentence2ids(args, example[0], word2id)\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "        padding_length = args.max_seq_length - len(input_ids)\n",
    "        input_ids = input_ids + ([0] * padding_length)\n",
    "        attention_mask = attention_mask + ([0] * padding_length)\n",
    "\n",
    "        label = int(example[1])\n",
    "\n",
    "        input_ids = input_ids[:args.max_seq_length]\n",
    "        attention_mask = attention_mask[:args.max_seq_length]\n",
    "        \n",
    "        features.append((input_ids, attention_mask, label))\n",
    "       \n",
    "        if ex_index == 1:\n",
    "            print('input_sentence: ', example[0])\n",
    "            print('input_ids: ', input_ids)\n",
    "            print('attention_mask: ', attention_mask)            \n",
    "            print('input_label: ', example[1])\n",
    "            print('label: ', label)\n",
    "        \n",
    "        \n",
    "    \n",
    "    all_input_ids = torch.tensor([f[0] for f in features], dtype=torch.long)\n",
    "    all_attention_mask = torch.tensor([f[1] for f in features], dtype=torch.long)\n",
    "    all_labels = torch.tensor([f[2] for f in features], dtype=torch.long)\n",
    "\n",
    "    # print('1:', len(all_labels))\n",
    "    dataset = TensorDataset(all_input_ids, all_attention_mask, all_labels)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "\n",
    "def train(args, train_dataset, model, tokenizer, word2id):\n",
    "    \"\"\" Train the model \"\"\"\n",
    "\n",
    "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
    "    print('train_dataset:', len(train_dataset))\n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n",
    "\n",
    "    t_total = len(train_dataloader) * args.num_train_epochs\n",
    "\n",
    "    \"\"\"\n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": args.weight_decay,\n",
    "        },\n",
    "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "\n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
    "    )\n",
    "\n",
    "    # Check if saved optimizer or scheduler states exist\n",
    "    if os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\")) and os.path.isfile(\n",
    "        os.path.join(args.model_name_or_path, \"scheduler.pt\")\n",
    "    ):\n",
    "        # Load in optimizer and scheduler states\n",
    "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
    "        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n",
    "    \"\"\"\n",
    "\n",
    "    # multi-gpu training (should be after apex fp16 initialization)\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    \"\"\"\n",
    "    \n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": args.weight_decay,\n",
    "        },\n",
    "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "    \"\"\"\n",
    "    # optimizer = torch.optim.Adam(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "    # Train!\n",
    "    \n",
    "    global_step = 0\n",
    "    epochs_trained = 0\n",
    "    steps_trained_in_current_epoch = 0\n",
    "    # Check if continuing training from a checkpoint\n",
    "    \n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.zero_grad()\n",
    "\n",
    "    train_iterator = range(epochs_trained, int(args.num_train_epochs))\n",
    "    set_seed(args)  # Added here for reproductibility\n",
    "    \n",
    "    loss_show = []\n",
    "    \n",
    "    for _ in train_iterator:\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        # epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "        epoch_iterator = train_dataloader\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "\n",
    "            model.train()\n",
    "            batch = tuple(t.to(args.device) for t in batch)\n",
    "            inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]  # model outputs are always tuple \n",
    "\n",
    "            if args.n_gpu > 1:\n",
    "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            loss_show.append(loss.item())\n",
    "            if(step + 1) % args.logging_steps == 0:\n",
    "                print('train step:', step, 'total step:', len(epoch_iterator))\n",
    "            \n",
    "            \n",
    "            optimizer.step()\n",
    "            # scheduler.step()  # Update learning rate schedule\n",
    "\n",
    "            model.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "    \n",
    "\n",
    "        print(\" train average loss = %s\", epoch_loss / step)\n",
    "        \n",
    "        # evaluate\n",
    "        dev_dataset = load_dataset(args, word2id, 'dev')\n",
    "        f1 = evaluate(args, dev_dataset, model, tokenizer, word2id)\n",
    "        \n",
    "    # show loss pic\n",
    "    x = []\n",
    "    y = loss_show\n",
    "    for i in range(len(y)):\n",
    "        x.append(i)\n",
    "\n",
    "    \n",
    "    plt.plot(x, y)\n",
    "    plt.title('Loss Change')\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return global_step, tr_loss / global_step\n",
    "\n",
    "\n",
    "def evaluate(args, eval_dataset, model, tokenizer, word2id):\n",
    "\n",
    "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
    "    # Note that DistributedSampler samples randomly\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
    "\n",
    "    # multi-gpu eval\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Eval!\n",
    "    print(\"***** Running evaluation *****\")\n",
    "    print(\"  Num examples = %d\", len(eval_dataset))\n",
    "    print(\"  Batch size = %d\", args.eval_batch_size)\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(args.device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "            outputs = model(**inputs)\n",
    "            tmp_eval_loss, logits = outputs\n",
    "\n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "\n",
    "\n",
    "    result = accuracy_score(out_label_ids, preds)\n",
    "    print(\"eval average loss = %s, accuracy_score = %s\", eval_loss, result)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--data_dir\", default='news', type=str)\n",
    "    parser.add_argument(\"--output_dir\", default='output', type=str)\n",
    "\n",
    "    # Other parameters\n",
    "    parser.add_argument(\"--max_seq_length\", default=32, type=int)\n",
    "    parser.add_argument(\"--num_train_epochs\", default=5, type=float)\n",
    "    parser.add_argument(\"--do_train\", default=True, type=bool)\n",
    "    parser.add_argument(\"--do_test\", default=True, type=bool)\n",
    "    parser.add_argument(\"--do_lower_case\", default=True, type=bool)\n",
    "    parser.add_argument(\"--per_gpu_train_batch_size\", default=64, type=int)\n",
    "    parser.add_argument(\"--per_gpu_eval_batch_size\", default=8, type=int)\n",
    "    parser.add_argument(\"--learning_rate\", default=1e-3, type=float)\n",
    "    parser.add_argument(\"--weight_decay\", default=0.01, type=float)\n",
    "    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float)\n",
    "    parser.add_argument(\"--no_cuda\", default=True, type=bool)\n",
    "    parser.add_argument(\"--seed\", default=42, type=int)\n",
    "    \n",
    "    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n",
    "    parser.add_argument(\"--gradient_accumulation_steps\", type=int, default=1, help=\"Number of updates steps to accumulate before performing a backward/update pass.\",)\n",
    "    parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
    "    parser.add_argument(\"--logging_steps\", type=int, default=100, help=\"Log every X updates steps.\")\n",
    "    parser.add_argument(\"--save_steps\", type=int, default=500, help=\"Save checkpoint every X updates steps.\")\n",
    "    parser.add_argument(\"--max_steps\", default=-1, type=int, help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\",)\n",
    "    parser.add_argument(\"--eval_all_checkpoints\", action=\"store_true\", help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",)\n",
    "    \n",
    "\n",
    "    # args = parser.parse_args()\n",
    "    args = parser.parse_args(args=[])\n",
    "\n",
    "    # Setup CUDA, GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "    args.n_gpu = torch.cuda.device_count()\n",
    "    args.device = device\n",
    "\n",
    "    \n",
    "\n",
    "    # Set seed\n",
    "    set_seed(args)\n",
    "    \n",
    "    # Set Label\n",
    "    label_list = ['0', '1', '2', '3', '4', '5', '6', '7' , '8', '9']\n",
    "    \n",
    "    # Set Vocab\n",
    "    vocab, word2id = load_vocab(args)\n",
    "    \n",
    "    # Build Model\n",
    "    model = Model(config())\n",
    "    model.to(args.device)\n",
    "\n",
    "    print(\"Training parameters %s\", args)\n",
    "\n",
    "    # Training\n",
    "    if args.do_train:\n",
    "        train_dataset = load_dataset(args, word2id, 'train')\n",
    "        global_step, tr_loss = train(args, train_dataset, model, vocab, word2id)\n",
    "        print(\"global_step = %s, average loss = %s\", global_step, tr_loss)\n",
    "        \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training parameters %s Namespace(adam_epsilon=1e-08, data_dir='news', device=device(type='cpu'), do_lower_case=True, do_test=True, do_train=True, eval_all_checkpoints=False, gradient_accumulation_steps=1, learning_rate=0.001, logging_steps=100, max_grad_norm=1.0, max_seq_length=32, max_steps=-1, n_gpu=0, no_cuda=True, num_train_epochs=5, output_dir='output', per_gpu_eval_batch_size=8, per_gpu_train_batch_size=64, save_steps=500, seed=42, warmup_steps=0, weight_decay=0.01)\n",
      "Writing example 0/10000\n",
      "input_sentence:  两天价网站背后重重迷雾：做个网站究竟要多少钱\n",
      "input_ids:  [146, 86, 35, 57, 496, 990, 75, 103, 103, 676, 2286, 6, 487, 184, 57, 496, 626, 1139, 186, 127, 420, 553, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_mask:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "input_label:  4\n",
      "label:  4\n",
      "train_dataset: 10000\n",
      "train step: 99 total step: 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Evaluating:   0%|          | 0/1250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train average loss = %s 1.0745234118822293\n",
      "Writing example 0/10000\n",
      "input_sentence:  60年铁树开花形状似玉米芯(组图)\n",
      "input_ids:  [30, 3, 14, 570, 1356, 33, 366, 893, 839, 1274, 1084, 259, 1302, 10, 78, 9, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_mask:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "input_label:  5\n",
      "label:  5\n",
      "***** Running evaluation *****\n",
      "  Num examples = %d 10000\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1250/1250 [00:24<00:00, 51.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval average loss = %s, accuracy_score = %s 0.8695391731292009 0.7258\n",
      "train step: 99 total step: 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Evaluating:   0%|          | 0/1250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train average loss = %s 0.48533047038393146\n",
      "Writing example 0/10000\n",
      "input_sentence:  60年铁树开花形状似玉米芯(组图)\n",
      "input_ids:  [30, 3, 14, 570, 1356, 33, 366, 893, 839, 1274, 1084, 259, 1302, 10, 78, 9, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_mask:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "input_label:  5\n",
      "label:  5\n",
      "***** Running evaluation *****\n",
      "  Num examples = %d 10000\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1250/1250 [00:23<00:00, 52.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval average loss = %s, accuracy_score = %s 0.7901264472857118 0.7651\n",
      "train step: 99 total step: 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Evaluating:   0%|          | 0/1250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train average loss = %s 0.22157123460410497\n",
      "Writing example 0/10000\n",
      "input_sentence:  60年铁树开花形状似玉米芯(组图)\n",
      "input_ids:  [30, 3, 14, 570, 1356, 33, 366, 893, 839, 1274, 1084, 259, 1302, 10, 78, 9, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_mask:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "input_label:  5\n",
      "label:  5\n",
      "***** Running evaluation *****\n",
      "  Num examples = %d 10000\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1250/1250 [00:23<00:00, 52.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval average loss = %s, accuracy_score = %s 0.8070584671553225 0.7772\n",
      "train step: 99 total step: 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Evaluating:   0%|          | 0/1250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train average loss = %s 0.10342866236057419\n",
      "Writing example 0/10000\n",
      "input_sentence:  60年铁树开花形状似玉米芯(组图)\n",
      "input_ids:  [30, 3, 14, 570, 1356, 33, 366, 893, 839, 1274, 1084, 259, 1302, 10, 78, 9, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_mask:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "input_label:  5\n",
      "label:  5\n",
      "***** Running evaluation *****\n",
      "  Num examples = %d 10000\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1250/1250 [00:23<00:00, 53.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval average loss = %s, accuracy_score = %s 0.8922916514568496 0.7833\n",
      "train step: 99 total step: 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Evaluating:   0%|          | 0/1250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train average loss = %s 0.03239785362548458\n",
      "Writing example 0/10000\n",
      "input_sentence:  60年铁树开花形状似玉米芯(组图)\n",
      "input_ids:  [30, 3, 14, 570, 1356, 33, 366, 893, 839, 1274, 1084, 259, 1302, 10, 78, 9, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_mask:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "input_label:  5\n",
      "label:  5\n",
      "***** Running evaluation *****\n",
      "  Num examples = %d 10000\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1250/1250 [00:22<00:00, 54.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval average loss = %s, accuracy_score = %s 0.9578899842447834 0.7803\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step = %s, average loss = %s 785 0.38100796780329504\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
